# Local Chat â€” Changli UI

ğŸš§ **Status:** This project is still in **development**, so expect bugs, incomplete features, and potential breaking changes. ğŸš§

---

## ğŸ“– Description
Local Chat is an **offline/local AI chat application** featuring:
- **Backend** built with Flask â†’ for API communication and chat storage.
- **Frontend (UI)** built with PySide6 (Qt) â†’ for an interactive chat interface.
- **Ollama Integration** â†’ to run local AI models (example: `gemma3:4b`).

This project is designed to run AI **fully locally**, with customizable identity, persona, and chat history.

---

## ğŸ“‚ Project Structure
```
local-ai-assistant/
â”œâ”€ app.py                    
â”‚
â”œâ”€ backend/
â”‚  â”œâ”€ config.py      
â”‚  â”œâ”€ core.py           
â”‚  â”œâ”€ persona.py            
â”‚  â”œâ”€ storage.py             
â”‚  â”œâ”€ ollama_client.py       
â”‚  â””â”€ routes.py              
â”‚
â”œâ”€ ui/
â”‚  â”œâ”€ main.py               
â”‚  â”œâ”€ chat_window.py         
â”‚  â”œâ”€ client.py              
â”‚  â”œâ”€ worker.py              
â”‚  â””â”€ widgets/              
â”‚     â”œâ”€ settings.py         
â”‚     â”œâ”€ history.py          
â”‚     â”œâ”€ bubbles.py          
â”‚     â””â”€ identity.py        
â”‚
â”œâ”€ data/                    
â”‚  â”œâ”€ chat_history.json
â”‚  â”œâ”€ chat_sessions.json
â”‚  â”œâ”€ ui_chat_config.json
â”‚  â””â”€ config.json
â”‚
â””â”€ README.md                 
```

---

## âš¡ Features
- ğŸ–¥ **Modern UI** using PySide6 (Qt)
- ğŸ“ **Chat History** â†’ rename, delete, or continue past sessions
- ğŸ­ **Custom Persona** â†’ change AI name, user name, and prompt
- ğŸ¨ **Custom Background** â†’ solid color or custom image
- âš™ï¸ **Flask Backend** with `/chat`, `/chats`, `/config` endpoints
- ğŸ¤– **Ollama Integration** â†’ run local AI models such as `gemma3:4b`
- ğŸ“‚ All data & configs stored locally under `data/`

---

## ğŸ› ï¸ Installation & Setup

### 1. Clone Repository
```bash
git clone https://github.com/rillToMe/local-chat.git
cd local-ai-assistant
```

### 2. Create Virtual Environment (recommended)
```bash
python -m venv venv
source venv/bin/activate     # Linux/Mac
venv\Scripts\activate        # Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

**Main dependencies:**
- `flask`
- `flask-cors`
- `requests`
- `PySide6`

> âš ï¸ **Note**: Make sure you have installed **[Ollama](https://ollama.ai/)** and the required model (`gemma3:4b`).

### 4. Run the App
```bash
python app.py
```

- Flask backend will start on `http://127.0.0.1:5000`
- PySide6 UI will automatically open

---

## ğŸ® Usage
- Click **Settings** â†’ change background or update **Identity & Prompt**
- Click **History** â†’ view, rename, or continue previous sessions
- Click **Clear** â†’ start a new conversation
- Default AI identity is **Changli** (can be changed via settings)

---

## ğŸ“Œ Roadmap / Todo
- [ ] Fix UI crash bugs
- [ ] Add model selection from UI (Ollama integration)
- [ ] Add chat export/import
- [ ] Add multi-tab chat support
- [ ] Optimize performance for long requests

---

## âš ï¸ Notes
- This is still in **early development**, expect frequent bugs and issues  
- UI/UX is minimal for now, focused on core functionality  
- Default persona is simple, can be extended with custom prompts  
